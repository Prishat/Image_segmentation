{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input\n",
    "from keras.layers.core import Dropout, Lambda\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras import backend as K\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path1='C:/Users/Prishat/Desktop/project-2/binarization/Original'\n",
    "path2='C:/Users/Prishat/Desktop/project-2/binarization/Marked'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_imlist(path):\n",
    "    return [os.path.join(f) for f in os.listdir(path) if f.endswith('.jpg')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "height=128\n",
    "width=128\n",
    "chanels=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Original_list=get_imlist(path1)\n",
    "Marked_list=get_imlist(path2)\n",
    "\n",
    "Original=np.array([np.array(Image.open(path1+'\\\\'+im).convert('L').resize((128,128))) for im in Original_list])\n",
    "Marked=np.array([np.array(Image.open(path2+'\\\\'+im).convert('L').resize((128,128))) for im in Marked_list])//255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(497, 128, 128, 1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Original_=Original[...,None]\n",
    "Marked_=Marked[...,None]\n",
    "m,n,j,g=Marked_.shape[0:4]\n",
    "m,n,j,g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 128, 128, 1)\n",
      "(447, 128, 128, 1)\n",
      "(50, 128, 128, 1)\n",
      "(447, 128, 128, 1)\n"
     ]
    }
   ],
   "source": [
    "l=int(m*0.9)\n",
    "\n",
    "im_test=Original[l:]\n",
    "im_test=im_test[...,None]\n",
    "\n",
    "im_train=Original[:l]\n",
    "im_train=im_train[...,None]\n",
    "\n",
    "te_lab=Marked[l:]\n",
    "te_lab=te_lab[...,None]\n",
    "\n",
    "tr_lab=Marked[:l]\n",
    "tr_lab=tr_lab[...,None]\n",
    "print(im_test.shape)\n",
    "print(im_train.shape)\n",
    "print(te_lab.shape)\n",
    "print(tr_lab.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 128, 128, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 128, 128, 16) 160         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 128, 128, 16) 0           conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 128, 128, 16) 2320        dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 64, 64, 16)   0           conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 64, 64, 32)   4640        max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 64, 64, 32)   0           conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 64, 64, 32)   9248        dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 32, 32, 32)   0           conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 32, 32, 64)   18496       max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 32, 32, 64)   0           conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 32, 32, 64)   36928       dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)  (None, 16, 16, 64)   0           conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 16, 16, 128)  73856       max_pooling2d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 16, 16, 128)  0           conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 16, 16, 128)  147584      dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2D)  (None, 8, 8, 128)    0           conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 8, 8, 256)    295168      max_pooling2d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 8, 8, 256)    0           conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 8, 8, 256)    590080      dropout_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_5 (Conv2DTrans (None, 16, 16, 128)  131200      conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 16, 16, 256)  0           conv2d_transpose_5[0][0]         \n",
      "                                                                 conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 16, 16, 128)  295040      concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 16, 16, 128)  0           conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 16, 16, 128)  147584      dropout_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_6 (Conv2DTrans (None, 32, 32, 64)   32832       conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 32, 32, 128)  0           conv2d_transpose_6[0][0]         \n",
      "                                                                 conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 32, 32, 64)   73792       concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)            (None, 32, 32, 64)   0           conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 32, 32, 64)   36928       dropout_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_7 (Conv2DTrans (None, 64, 64, 32)   8224        conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 64, 64, 64)   0           conv2d_transpose_7[0][0]         \n",
      "                                                                 conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 64, 64, 32)   18464       concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)            (None, 64, 64, 32)   0           conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 64, 64, 32)   9248        dropout_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_8 (Conv2DTrans (None, 128, 128, 16) 2064        conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 128, 128, 32) 0           conv2d_transpose_8[0][0]         \n",
      "                                                                 conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 128, 128, 16) 4624        concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_18 (Dropout)            (None, 128, 128, 16) 0           conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 128, 128, 16) 2320        dropout_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 128, 128, 1)  17          conv2d_37[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,940,817\n",
      "Trainable params: 1,940,817\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "x=Input(shape=(height,width,chanels))\n",
    "inp=x\n",
    "\n",
    "conv1= Conv2D(16,(3,3),activation='elu',padding='same')(inp)\n",
    "conv1=Dropout(0.1)(conv1)\n",
    "conv1= Conv2D(16,(3,3),activation='elu',padding='same')(conv1)\n",
    "p1=MaxPooling2D((2,2))(conv1)\n",
    "\n",
    "conv2= Conv2D(32,(3,3),activation='elu',padding='same')(p1)\n",
    "conv2=Dropout(0.1)(conv2)\n",
    "conv2= Conv2D(32,(3,3),activation='elu',padding='same')(conv2)\n",
    "p2= MaxPooling2D((2,2))(conv2)\n",
    "\n",
    "conv3= Conv2D(64,(3,3),activation='elu',padding='same')(p2)\n",
    "conv3=Dropout(0.2)(conv3)\n",
    "conv3= Conv2D(64,(3,3),activation='elu',padding='same')(conv3)\n",
    "p3= MaxPooling2D((2,2))(conv3)\n",
    "\n",
    "conv4= Conv2D(128,(3,3),activation='elu',padding='same')(p3)\n",
    "conv4=Dropout(0.2)(conv4)\n",
    "conv4= Conv2D(128,(3,3),activation='elu',padding='same')(conv4)\n",
    "p4= MaxPooling2D((2,2))(conv4)\n",
    "\n",
    "conv5= Conv2D(256,(3,3),activation='elu',padding='same')(p4)\n",
    "conv5=Dropout(0.3)(conv5)\n",
    "conv5= Conv2D(256,(3,3),activation='elu',padding='same')(conv5)\n",
    "\n",
    "up1=Conv2DTranspose(128,(2,2),strides=(2,2),padding='same')(conv5)\n",
    "up1= concatenate([up1,conv4])\n",
    "conv6= Conv2D(128,(3,3),activation='elu',padding='same')(up1)\n",
    "conv6=Dropout(0.2)(conv6)\n",
    "conv6= Conv2D(128,(3,3),activation='elu',padding='same')(conv6)\n",
    "\n",
    "up2=Conv2DTranspose(64,(2,2),strides=(2,2),padding='same')(conv6)\n",
    "up2= concatenate([up2,conv3])\n",
    "conv7= Conv2D(64,(3,3),activation='elu',padding='same')(up2)\n",
    "conv7=Dropout(0.2)(conv7)\n",
    "conv7= Conv2D(64,(3,3),activation='elu',padding='same')(conv7)\n",
    "\n",
    "up3=Conv2DTranspose(32,(2,2),strides=(2,2),padding='same')(conv7)\n",
    "up3= concatenate([up3,conv2])\n",
    "conv8= Conv2D(32,(3,3),activation='elu',padding='same')(up3)\n",
    "conv8=Dropout(0.1)(conv8)\n",
    "conv8= Conv2D(32,(3,3),activation='elu',padding='same')(conv8)\n",
    "\n",
    "up4=Conv2DTranspose(16,(2,2),strides=(2,2),padding='same')(conv8)\n",
    "up4= concatenate([up4,conv1])\n",
    "conv9= Conv2D(16,(3,3),activation='elu',padding='same')(up4)\n",
    "conv9=Dropout(0.1)(conv9)\n",
    "conv9= Conv2D(16,(3,3),activation='elu',padding='same')(conv9)\n",
    "\n",
    "out=Conv2D(1,(1,1),activation='sigmoid')(conv9)\n",
    "\n",
    "model=Model(x,out)\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 402 samples, validate on 45 samples\n",
      "Epoch 1/20\n",
      "402/402 [==============================] - 141s 352ms/step - loss: 0.8720 - acc: 0.8078 - val_loss: 0.4221 - val_acc: 0.8341\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.42214, saving model to UNet_model_2.h5\n",
      "Epoch 2/20\n",
      "402/402 [==============================] - 139s 345ms/step - loss: 0.3149 - acc: 0.8907 - val_loss: 0.3161 - val_acc: 0.8899\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.42214 to 0.31612, saving model to UNet_model_2.h5\n",
      "Epoch 3/20\n",
      "402/402 [==============================] - 139s 345ms/step - loss: 0.2700 - acc: 0.9144 - val_loss: 0.2802 - val_acc: 0.9104\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.31612 to 0.28021, saving model to UNet_model_2.h5\n",
      "Epoch 4/20\n",
      "402/402 [==============================] - 139s 345ms/step - loss: 0.2628 - acc: 0.9183 - val_loss: 0.2705 - val_acc: 0.9129\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.28021 to 0.27052, saving model to UNet_model_2.h5\n",
      "Epoch 5/20\n",
      "402/402 [==============================] - 139s 345ms/step - loss: 0.2402 - acc: 0.9222 - val_loss: 0.3114 - val_acc: 0.8907\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.27052\n",
      "Epoch 6/20\n",
      "402/402 [==============================] - 139s 346ms/step - loss: 0.2203 - acc: 0.9262 - val_loss: 0.1994 - val_acc: 0.9218\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.27052 to 0.19943, saving model to UNet_model_2.h5\n",
      "Epoch 7/20\n",
      "402/402 [==============================] - 139s 346ms/step - loss: 0.1661 - acc: 0.9342 - val_loss: 0.1906 - val_acc: 0.9261\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.19943 to 0.19055, saving model to UNet_model_2.h5\n",
      "Epoch 8/20\n",
      "402/402 [==============================] - 142s 353ms/step - loss: 0.1410 - acc: 0.9412 - val_loss: 0.1602 - val_acc: 0.9366\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.19055 to 0.16023, saving model to UNet_model_2.h5\n",
      "Epoch 9/20\n",
      "402/402 [==============================] - 142s 354ms/step - loss: 0.1205 - acc: 0.9516 - val_loss: 0.1405 - val_acc: 0.9443\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.16023 to 0.14047, saving model to UNet_model_2.h5\n",
      "Epoch 10/20\n",
      "402/402 [==============================] - 140s 347ms/step - loss: 0.1128 - acc: 0.9553 - val_loss: 0.1343 - val_acc: 0.9449\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.14047 to 0.13426, saving model to UNet_model_2.h5\n",
      "Epoch 11/20\n",
      "402/402 [==============================] - 142s 353ms/step - loss: 0.1078 - acc: 0.9573 - val_loss: 0.1380 - val_acc: 0.9472\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.13426\n",
      "Epoch 12/20\n",
      "402/402 [==============================] - 141s 350ms/step - loss: 0.1002 - acc: 0.9593 - val_loss: 0.1265 - val_acc: 0.9492\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.13426 to 0.12648, saving model to UNet_model_2.h5\n",
      "Epoch 13/20\n",
      "402/402 [==============================] - 141s 351ms/step - loss: 0.0957 - acc: 0.9604 - val_loss: 0.1241 - val_acc: 0.9518\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.12648 to 0.12409, saving model to UNet_model_2.h5\n",
      "Epoch 14/20\n",
      "402/402 [==============================] - 142s 353ms/step - loss: 0.0981 - acc: 0.9593 - val_loss: 0.1205 - val_acc: 0.9509\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.12409 to 0.12048, saving model to UNet_model_2.h5\n",
      "Epoch 15/20\n",
      "402/402 [==============================] - 141s 352ms/step - loss: 0.1013 - acc: 0.9588 - val_loss: 0.1334 - val_acc: 0.9469\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.12048\n",
      "Epoch 16/20\n",
      "402/402 [==============================] - 140s 349ms/step - loss: 0.0936 - acc: 0.9607 - val_loss: 0.1098 - val_acc: 0.9541\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.12048 to 0.10977, saving model to UNet_model_2.h5\n",
      "Epoch 17/20\n",
      "402/402 [==============================] - 138s 344ms/step - loss: 0.0863 - acc: 0.9630 - val_loss: 0.0964 - val_acc: 0.9556\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.10977 to 0.09636, saving model to UNet_model_2.h5\n",
      "Epoch 18/20\n",
      "402/402 [==============================] - 139s 345ms/step - loss: 0.1198 - acc: 0.9545 - val_loss: 0.1437 - val_acc: 0.9431\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.09636\n",
      "Epoch 19/20\n",
      "402/402 [==============================] - 139s 345ms/step - loss: 0.0981 - acc: 0.9600 - val_loss: 0.1029 - val_acc: 0.9568\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.09636\n",
      "Epoch 20/20\n",
      "402/402 [==============================] - 138s 344ms/step - loss: 0.1016 - acc: 0.9583 - val_loss: 0.1008 - val_acc: 0.9570\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.09636\n"
     ]
    }
   ],
   "source": [
    "earlystopper= EarlyStopping(patience=3)\n",
    "checkpoint= ModelCheckpoint('UNet_model_2.h5',verbose=1,save_best_only=True)\n",
    "history=model.fit(im_train,tr_lab,validation_split=0.1,batch_size=16,epochs=20,callbacks=[earlystopper,checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=load_model('UNet_model_2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tr=model.predict(im_test[0:10])\n",
    "for k in tr:\n",
    "    for i in range(len(k)):\n",
    "        for j in range(len(k[0])):\n",
    "            if k[i][j]>0.40:\n",
    "                k[i][j]=1\n",
    "            else:\n",
    "                k[i][j]=0\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[255.],\n",
       "         [255.],\n",
       "         [255.],\n",
       "         ...,\n",
       "         [255.],\n",
       "         [255.],\n",
       "         [255.]],\n",
       "\n",
       "        [[255.],\n",
       "         [255.],\n",
       "         [255.],\n",
       "         ...,\n",
       "         [255.],\n",
       "         [255.],\n",
       "         [255.]],\n",
       "\n",
       "        [[255.],\n",
       "         [255.],\n",
       "         [255.],\n",
       "         ...,\n",
       "         [255.],\n",
       "         [255.],\n",
       "         [255.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[255.],\n",
       "         [255.],\n",
       "         [255.],\n",
       "         ...,\n",
       "         [255.],\n",
       "         [255.],\n",
       "         [255.]],\n",
       "\n",
       "        [[255.],\n",
       "         [255.],\n",
       "         [255.],\n",
       "         ...,\n",
       "         [255.],\n",
       "         [255.],\n",
       "         [255.]],\n",
       "\n",
       "        [[255.],\n",
       "         [255.],\n",
       "         [255.],\n",
       "         ...,\n",
       "         [255.],\n",
       "         [255.],\n",
       "         [255.]]],\n",
       "\n",
       "\n",
       "       [[[255.],\n",
       "         [255.],\n",
       "         [255.],\n",
       "         ...,\n",
       "         [255.],\n",
       "         [255.],\n",
       "         [255.]],\n",
       "\n",
       "        [[255.],\n",
       "         [255.],\n",
       "         [255.],\n",
       "         ...,\n",
       "         [255.],\n",
       "         [255.],\n",
       "         [255.]],\n",
       "\n",
       "        [[255.],\n",
       "         [255.],\n",
       "         [255.],\n",
       "         ...,\n",
       "         [255.],\n",
       "         [255.],\n",
       "         [255.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[255.],\n",
       "         [255.],\n",
       "         [255.],\n",
       "         ...,\n",
       "         [255.],\n",
       "         [255.],\n",
       "         [255.]],\n",
       "\n",
       "        [[255.],\n",
       "         [255.],\n",
       "         [255.],\n",
       "         ...,\n",
       "         [255.],\n",
       "         [255.],\n",
       "         [255.]],\n",
       "\n",
       "        [[255.],\n",
       "         [255.],\n",
       "         [255.],\n",
       "         ...,\n",
       "         [255.],\n",
       "         [255.],\n",
       "         [255.]]],\n",
       "\n",
       "\n",
       "       [[[255.],\n",
       "         [255.],\n",
       "         [255.],\n",
       "         ...,\n",
       "         [255.],\n",
       "         [255.],\n",
       "         [255.]],\n",
       "\n",
       "        [[255.],\n",
       "         [255.],\n",
       "         [255.],\n",
       "         ...,\n",
       "         [255.],\n",
       "         [255.],\n",
       "         [255.]],\n",
       "\n",
       "        [[255.],\n",
       "         [255.],\n",
       "         [255.],\n",
       "         ...,\n",
       "         [255.],\n",
       "         [255.],\n",
       "         [255.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[255.],\n",
       "         [255.],\n",
       "         [255.],\n",
       "         ...,\n",
       "         [255.],\n",
       "         [255.],\n",
       "         [255.]],\n",
       "\n",
       "        [[255.],\n",
       "         [255.],\n",
       "         [255.],\n",
       "         ...,\n",
       "         [255.],\n",
       "         [255.],\n",
       "         [255.]],\n",
       "\n",
       "        [[255.],\n",
       "         [255.],\n",
       "         [255.],\n",
       "         ...,\n",
       "         [255.],\n",
       "         [255.],\n",
       "         [255.]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[255.],\n",
       "         [255.],\n",
       "         [255.],\n",
       "         ...,\n",
       "         [255.],\n",
       "         [255.],\n",
       "         [255.]],\n",
       "\n",
       "        [[255.],\n",
       "         [255.],\n",
       "         [255.],\n",
       "         ...,\n",
       "         [255.],\n",
       "         [255.],\n",
       "         [255.]],\n",
       "\n",
       "        [[255.],\n",
       "         [255.],\n",
       "         [255.],\n",
       "         ...,\n",
       "         [255.],\n",
       "         [255.],\n",
       "         [255.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[  0.],\n",
       "         [  0.],\n",
       "         [  0.],\n",
       "         ...,\n",
       "         [255.],\n",
       "         [255.],\n",
       "         [255.]],\n",
       "\n",
       "        [[  0.],\n",
       "         [  0.],\n",
       "         [  0.],\n",
       "         ...,\n",
       "         [255.],\n",
       "         [255.],\n",
       "         [255.]],\n",
       "\n",
       "        [[  0.],\n",
       "         [255.],\n",
       "         [  0.],\n",
       "         ...,\n",
       "         [255.],\n",
       "         [255.],\n",
       "         [255.]]],\n",
       "\n",
       "\n",
       "       [[[255.],\n",
       "         [255.],\n",
       "         [255.],\n",
       "         ...,\n",
       "         [  0.],\n",
       "         [  0.],\n",
       "         [  0.]],\n",
       "\n",
       "        [[255.],\n",
       "         [255.],\n",
       "         [255.],\n",
       "         ...,\n",
       "         [  0.],\n",
       "         [  0.],\n",
       "         [  0.]],\n",
       "\n",
       "        [[255.],\n",
       "         [255.],\n",
       "         [255.],\n",
       "         ...,\n",
       "         [  0.],\n",
       "         [  0.],\n",
       "         [  0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[255.],\n",
       "         [255.],\n",
       "         [255.],\n",
       "         ...,\n",
       "         [255.],\n",
       "         [255.],\n",
       "         [255.]],\n",
       "\n",
       "        [[255.],\n",
       "         [255.],\n",
       "         [255.],\n",
       "         ...,\n",
       "         [255.],\n",
       "         [255.],\n",
       "         [255.]],\n",
       "\n",
       "        [[255.],\n",
       "         [255.],\n",
       "         [255.],\n",
       "         ...,\n",
       "         [255.],\n",
       "         [255.],\n",
       "         [255.]]],\n",
       "\n",
       "\n",
       "       [[[  0.],\n",
       "         [  0.],\n",
       "         [  0.],\n",
       "         ...,\n",
       "         [255.],\n",
       "         [255.],\n",
       "         [  0.]],\n",
       "\n",
       "        [[  0.],\n",
       "         [  0.],\n",
       "         [  0.],\n",
       "         ...,\n",
       "         [255.],\n",
       "         [255.],\n",
       "         [255.]],\n",
       "\n",
       "        [[  0.],\n",
       "         [  0.],\n",
       "         [  0.],\n",
       "         ...,\n",
       "         [255.],\n",
       "         [255.],\n",
       "         [255.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[255.],\n",
       "         [255.],\n",
       "         [255.],\n",
       "         ...,\n",
       "         [255.],\n",
       "         [255.],\n",
       "         [255.]],\n",
       "\n",
       "        [[255.],\n",
       "         [255.],\n",
       "         [255.],\n",
       "         ...,\n",
       "         [255.],\n",
       "         [255.],\n",
       "         [255.]],\n",
       "\n",
       "        [[255.],\n",
       "         [255.],\n",
       "         [255.],\n",
       "         ...,\n",
       "         [255.],\n",
       "         [255.],\n",
       "         [255.]]]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr=tr*255\n",
    "tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=128x128 at 0x2270119D908>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imo=np.array(im_test[2])\n",
    "imo=imo.reshape((128,128))\n",
    "imo=Image.fromarray(imo)\n",
    "#imo=imo.convert('RGB')\n",
    "#imo.show()\n",
    "imo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIAAAACACAAAAADmVT4XAAABdElEQVR4nO2a23LCMAxEo07//5fVJxgaauPVJYbO8SuOdLJaK46D+bF3fG3ODwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABQBmDhCxOfbs3NzU+p1XgZgOFtuxA1pcDsx9W4QYC1kq/EjpjQVi1nC/MiCmiOf5EgoIC64ubzVQVC632WQwQI95thGg0gnH/MIHkglX9w9XcqZoDgrIOiQE6AUVCha9dlfUi6Zz/wcC+bNiR2b+d7SnAbrijQYUF7gz3hlX3gj2GCAk3/+9teAgHAWzQQPNDSiSUFdgP0EEgm7CC4cEOSB2hxoeSB7SU43Mt9IHfC6jrIANV1CL0dV6oQehhVqhB7GhZKEDofSJ3rnIOFYxWp8EkbkrcDqDFCHKCoK2dKUGLD9HuB2/1k1Pw4no5uX43KJX0LKc1uWAVSo/aOZbgsgR/eUYLnMTvTvwTgpMmvlNcATMYnt2IAAAAAAAAAAACAfwLwA7btQOw27aX/AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=128x128 at 0x2277822DF98>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp=np.array(tr[2])\n",
    "imp=imp.reshape((128,128))\n",
    "imp=Image.fromarray(imp)\n",
    "imp=imp.convert('L')\n",
    "#imp.show()\n",
    "imp"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
